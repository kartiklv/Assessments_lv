# -*- coding: utf-8 -*-
"""lvadsusr159_b_kartik_lab1

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z9toZkJCzl6jjuan6WymmVmd-_VXcEuB
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from scipy.cluster.hierarchy import dendrogram, linkage
from scipy.cluster.hierarchy import fcluster
from sklearn.cluster import KMeans
from sklearn.preprocessing import MinMaxScaler,LabelEncoder

from sklearn.metrics import silhouette_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler,LabelEncoder
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report, f1_score

from sklearn.linear_model import LinearRegression


import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv("/content/Fare prediction.csv")
df.head(10)

df.shape

df.info()

df.describe(include='all')

df.dtypes

df.isnull().sum()

df.duplicated().sum()

from sklearn.impute import SimpleImputer
imp = SimpleImputer(strategy="mean")
df["pickup_latitude"]=imp.fit_transform(df[["pickup_latitude"]])
df["dropoff_longitude"]=imp.fit_transform(df[["dropoff_longitude"]])
df["dropoff_latitude"]=imp.fit_transform(df[["dropoff_latitude"]])
df["passenger_count"]=imp.fit_transform(df[["passenger_count"]])

df.isnull().sum()

df.dtypes

df["horsepower"]=pd.to_numeric(df['horsepower'],errors='coerce')

df.columns

#Null values
df.displacement = df['displacement'].fillna(df['displacement'].median())
df.acceleration = df['acceleration'].fillna(df['acceleration'].median())
df.horsepower = df['horsepower'].fillna(df['horsepower'].median())

#Boxplot to treat outliers
for column in df.select_dtypes(include=['int64','float64']).columns:
    plt.figure(figsize=(10, 6))  # Set the figure size for better readability
    sns.boxplot(x=df[column])
    plt.title(f'Box Plot of {column}')
    plt.xlabel(column)
    plt.show()

list = []
for cols in list:
  Q1 = df.cols.quantile(0.25)
  Q3 = df.cols.quantile(0.75)
  IQR = Q3-Q1
  lb = Q1-1.5*IQR
  ub = Q3+1.5*IQR
  df = df[(cols > lb) & (cols < ub)]

df.loc[df['displacement']>22.087,'displacement']=22.087
df.loc[df['displacement']<8.98,'displacement']=8.98

#Bivariate Analysis
#Correlation Matrix and HeatMap
num = df.select_dtypes(include=['float64','int64']).columns
correlation_matrix = df[num].corr()
print(correlation_matrix)

#Heatmap
sns.heatmap(correlation_matrix,annot=True)

df=df.drop(columns='pickup_datetime')
df=df.drop(columns='key')

for i in range(len(num)):
  for j in range(i+1,len(num)):
    sns.scatterplot(data=df,x=num[i],y=num[j])
    plt.title(f"Scatter plot between {num[i]} and {num[j]}")
    plt.xlabel(f"{num[i]}")
    plt.ylabel(f"{num[j]}")
    plt.show()

df.dtypes

df.dtypes

#Duplicate treatment
df.duplicated().sum()

df.drop_duplicates(inplace=True)

df.duplicated().sum()

df

d = df
X = d.drop(columns=['fare_amount'])
y = d['fare_amount']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

model = LinearRegression()
model.fit(X_train,y_train)

y_pred = model.predict(X_test)

mse = mean_squared_error(y_test,y_pred)
print("Mean Squared Error: ",mse)
rmse = mean_squared_error(y_test,y_pred,squared=False)
print("Root Mean Squared Error: ",rmse)
r2_s = r2_score(y_test,y_pred)
print("R2 Score",r2_s)